#include <Eigen/Dense>

class SimpleNNUE {
public:
    Eigen::MatrixXf weights1; // Input to hidden layer weights
    Eigen::VectorXf biases1;  // Hidden layer biases
    Eigen::MatrixXf weights2; // Hidden to output layer weights
    Eigen::VectorXf biases2;  // Output layer biases

    SimpleNNUE(int inputSize, int hiddenSize) {
        weights1 = Eigen::MatrixXf::Random(hiddenSize, inputSize);
        biases1 = Eigen::VectorXf::Random(hiddenSize);
        weights2 = Eigen::MatrixXf::Random(1, hiddenSize);
        biases2 = Eigen::VectorXf::Random(1);
    }

    float evaluate(const std::vector<float>& features) {
        Eigen::VectorXf input = Eigen::Map<const Eigen::VectorXf>(features.data(), features.size());

        // Feedforward to hidden layer
        Eigen::VectorXf hidden = (weights1 * input + biases1).array().max(0); // ReLU activation
        // Feedforward to output layer
        float output = (weights2.transpose() * hidden + biases2)(0,0);

        return output;
    }
};
